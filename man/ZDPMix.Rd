% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ZDPMix.r
\name{ZDPMix}
\alias{ZDPMix}
\title{Function for posterior sampling of DP mixture of zero-inflated regressions.}
\usage{
ZDPMix(d_train, formula, d_test = NULL, burnin, iter, phi_y = c(shape =
  5, rate = 1000), beta_prior_mean = NULL, beta_prior_var = NULL,
  gamma_prior_mean = NULL, gamma_prior_var = NULL, init_k = 10,
  beta_var_scale = 1000, mu_scale = 1, tau_scale = 1,
  prop_sigma_z = diag(rep(0.025, nparams)))
}
\arguments{
\item{d_train}{A \code{data.frame} object with outcomes and model covariates/features. All features must be \code{as.numeric} - either continuous or binary with binary variables coded using \code{1} and \code{0}. Categorical features are not supported. We recommend standardizing all continuous features. NA values are not allowed and each row should represent a single subject, longitudinal data is not supported.}

\item{formula}{Specified in the usual way, e.g. for \code{p=2} covariates, \code{y ~ x1 + x2}. All covariates - continuous and binary - must be \code{as.numeric} , with binary variables coded as \code{1} or \code{0}. We recommend standardizing all continuous features. NA values are not allowed and each row should represent a single subject, longitudinal data is not supported.}

\item{d_test}{Optional \code{data.frame} object containing a test set of subjects containing all variables specifed in \code{formula}. All the same rules for \code{d_train} apply to \code{d_test}.}

\item{burnin}{interger specifying number of burn-in MCMC draws.}

\item{iter}{interger greater than \code{burnin} specifying how many total MCMC draws to take.}

\item{phi_y}{Optional. Length two \code{as.numeric} vector specifying the shape and rate, respectively, of the Inverse Gamma hyper-prior placed on the outcome variance.}

\item{beta_prior_mean}{Optional. If there are \code{p} covariates, it is a length \code{p+1} \code{as.numeric} vector specifying mean of the Gaussian prior on the outcome model's conditional mean parameter vector. Default is regression coefficients from running OLS on positive outcomes.}

\item{beta_prior_var}{Optional. If there are \code{p} covariates, a length \code{p+1} \code{as.numeric} vector specifying variance of the Gaussian prior on the outcome model's conditional mean parameter vector. The full covarince of the prior is set to be diagonal. This vector specifies the diagonal enteries of this prior covariance. Default is estimated variances from running OLS on positive outcomes.}

\item{gamma_prior_mean}{Optional. If there are \code{p} covariates, a length \code{p+1} \code{as.numeric} vector specifying mean of the Gaussian prior on the zero probability logistic model's conditional mean parameter vector. Default is a vector of 0s - i.e., null-centered prior mean.}

\item{gamma_prior_var}{Optional. If there are \code{p} covariates, a length \code{p+1} \code{as.numeric} vector specifying variance of the Gaussian prior on the zero probability logistic model's conditional mean parameter vector. Default is vector of 2s - moderately flat on the odds ratio scale.}

\item{init_k}{Optional. Interger specifying the initial number of clusters to kick off the MCMC sampler.}

\item{beta_var_scale}{Optional. A multiplicative constant that scales \code{beta_prior_var}. If you leave \code{beta_prior_mean} and \code{beta_prior_var} at their defaults, This constant toggles how wide new cluster parameters are dispersed around the observed data parameters, larger values implies wider distribution.}

\item{mu_scale}{Optional. An numeric, scalar constant that controls how widely distributed new cluster continuous covariate means are distributed around the empirical covariate mean. Specifically, all continuous covariates are assumed to have Gaussian likelihood with Gaussian prior on their means. \code{mu_scale=2} specifies that the variance of the Gaussian prior is twice as large as the empirical variance.}

\item{tau_scale}{Optional. An numeric, scalar constant that controls how widely distributed new cluster continuous covariate variances are distributed around the empirical variance. Specifically, all continuous covariates are assumed to have Gaussian likelihood with Inverse Gamma prior on their variance. \code{tau_scale=2} specifies that the rate of the InvGamma prior is twice as large as the empirical variance.}

\item{prop_sigma_z}{Optional. If you specified \code{p} covariates in \code{formula}, \code{p+1} regression parameters are sampled for the probability of the outcome being zero using a Metropolis step.  \code{prop_sigma_z} is a \code{p+1} by \code{p+1} covariance matrix for the Metropolis proposal distribution.}
}
\value{
Returns \code{predictions$train} and \code{cluster_inds$train}. \code{predictions$train} returns an \code{nrow(d_train)} by \code{iter - burnin} matrix of posterior predictions. \code{cluster_inds$train} returns an \code{nrow(d_train)} by \code{iter - burnin} matrix of cluster assignment indicators, which can be input into the function \code{cluster_assign_mode()} to compute posterior mode assignment. \code{predictions$test} and \code{cluster_inds$test} are returned if \code{d_test} is specified.
}
\description{
This function takes in a training data.frame and optional testing data.frame and performs posterior sampling. It returns posterior predictions and posterior clustering for training and test sets.
The function is built for zero-inflated, but otherwise continuous, outcomes.
}
\details{
Please see \url{https://stablemarkets.github.io/ChiRPsite/index.html}for examples and detailed model and parameter descriptions.

Please see \url{https://arxiv.org/abs/1810.09494} for a methodological reference.
}
\examples{
set.seed(1)
n<-200 ## generate from clustered, skewed, data distribution
X11 <- rnorm(n = n, mean = 10, sd = 3)
X12 <- rnorm(n = n, mean = 0, sd = 2)
X13 <- rnorm(n = n, mean = -10, sd = 4)

Y1 <- rnorm(n = n, mean = 100 + .5*X11, 20)*(1-rbinom(n, 1, prob = pnorm( -10 + 1*X11 ) ))
Y2 <- rnorm(n = n, mean = 200 + 1*X12, 30)*(1-rbinom(n, 1, prob = pnorm( 1 + .05*X12 ) ))
Y3 <- rnorm(n = n, mean = 300 + 2*X13, 40)*(1-rbinom(n, 1, prob = pnorm( -3 -.2*X13 ) ))

d <- data.frame(X1=c(X11, X12, X13), Y = c(Y1, Y2, Y3))

d$X1 <- scale(d$X1)

ids <- sample(1:600, size = 500, replace = FALSE )
d_train <- d[ids,]
d_test <- d[-ids, ]

res <- ChiRP::ZDPMix(d_train = d_train, d_test = d_test, formula = Y ~ X1,
                     burnin=100, iter=200, init_k = 5, phi_y = c(10, 10000))
}
\keyword{Dirichlet}
\keyword{Inflated}
\keyword{Process}
\keyword{Zero}
